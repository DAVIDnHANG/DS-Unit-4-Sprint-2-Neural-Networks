{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "Neuron are part of aritifical neural network in machine learning which is inspired by the biological neural system\n",
    "- **Input Layer:**\n",
    "Each neuron receives input. These neruons takes the input on the input layer, * it by a weight, then\n",
    "add a bias. \n",
    "- **Activiation:**\n",
    " Once the sum is derived it is multiply by a sigmoid to squish the result between 0 and 1. Then it will activite,\n",
    " called an activiation function, to determine if it should send a signal to the next layers. But there is also some\n",
    " other activiation function such as Tanh, and ReLU.\n",
    "- **Hidden Layer:**\n",
    "The next layers is usually called the hidden function. This layers is not usually interactive with, \n",
    "but the user can  give the number of neurons. There can be zero to many hidden layers, but at the end it \n",
    "activate to an output layers.\n",
    "of nodes.\n",
    "- **Output Layer:**\n",
    "Output layer receives input from hidden layer and perform similar computation.\n",
    "- **Backpropagation:**\n",
    "A mechanics that allows the neuron to send a signal backwards. to adjust the weight and bias. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score \n",
    "import sklearn.datasets\n",
    "# Start your candy perceptron here\n",
    "url = 'F:\\\\Pycharm\\\\DS-Unit-4-Sprint-2-Neural-Networks\\\\DS_Unit4\\\\chocolate_gummy_bears.csv'\n",
    "candy = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "   chocolate  gummy  ate\n0          0      1    1\n1          1      0    1\n2          0      1    1\n3          0      0    0\n4          1      1    0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chocolate</th>\n      <th>gummy</th>\n      <th>ate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "candy.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "X = candy[[\"chocolate\",\"gummy\"]]\n",
    "y = candy[\"ate\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "   chocolate  gummy\n0          0      1\n1          1      0\n2          0      1\n3          0      0\n4          1      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chocolate</th>\n      <th>gummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 86
    }
   ],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.1, stratify = y, random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# perceptron.py\n",
    "import numpy as np\n",
    "\n",
    "class SinglePerceptron(object):\n",
    "   def __init__(self, rate = 0.01, niter = 10):\n",
    "      self.rate = rate\n",
    "      self.niter = niter\n",
    "\n",
    "   def fit(self, X, y):\n",
    "      \"\"\"Fit training data\n",
    "      X : Training vectors, X.shape : [#samples, #features]\n",
    "      y : Target values, y.shape : [#samples]\n",
    "      \"\"\"\n",
    "\n",
    "      # weights\n",
    "      self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "      # Number of misclassifications\n",
    "      self.errors = []  # Number of misclassifications\n",
    "\n",
    "      for i in range(self.niter):\n",
    "         err = 0\n",
    "         for xi, target in zip(X, y):\n",
    "            delta_w = self.rate * (target - self.predict(xi))\n",
    "            self.weight[1:] += delta_w * xi\n",
    "            self.weight[0] += delta_w\n",
    "            err += int(delta_w != 0.0)\n",
    "         self.errors.append(err)\n",
    "      return self\n",
    "\n",
    "   def net_input(self, X):\n",
    "      \"\"\"Calculate net input\"\"\"\n",
    "      return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "   def predict(self, X):\n",
    "      \"\"\"Return class label after unit step\"\"\"\n",
    "      return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SinglePerceptronTwo:\n",
    "  \n",
    "  #constructor\n",
    "  def __init__ (self):\n",
    "    self.w = None\n",
    "    self.b = None\n",
    "    \n",
    "  #model  \n",
    "  def model(self, x):\n",
    "    return 1 if (np.dot(self.w, x) >= self.b) else 0\n",
    "  \n",
    "  #predictor to predict on the data based on w\n",
    "  def predict(self, X):\n",
    "    Y = []\n",
    "    for x in X:\n",
    "      result = self.model(x)\n",
    "      Y.append(result)\n",
    "    return np.array(Y)\n",
    "    \n",
    "  def fit(self, input, labels, epochs = 1, learningrate = 1):\n",
    "    self.w = np.ones(X.shape[1])\n",
    "    self.b = 0\n",
    "    accuracy = {}\n",
    "    max_accuracy = 0\n",
    "    wt_matrix = []\n",
    "    #for all epochs\n",
    "    for i in range(epochs):\n",
    "      for x,y in zip(input, labels):\n",
    "        y_pred = self.model(x)\n",
    "        if y == 1 and y_pred == 0:\n",
    "          self.w = self.w + learningrate * x\n",
    "          self.b = self.b - learningrate * 1\n",
    "        elif y == 0 and y_pred == 1:\n",
    "          self.w = self.w - learningrate * x\n",
    "          self.b = self.b + learningrate * 1\n",
    "          \n",
    "      wt_matrix.append(self.w)    \n",
    "      accuracy[i] = accuracy_score(self.predict(X), labels)\n",
    "      if (accuracy[i] > max_accuracy):\n",
    "        max_accuracy = accuracy[i]\n",
    "        chkptw = self.w\n",
    "        chkptb = self.b\n",
    "    #checkpoint (Save the weights and b value)\n",
    "    self.w = chkptw\n",
    "    self.b = chkptb\n",
    "        \n",
    "    print(max_accuracy)\n",
    "    #plot the accuracy values over epochs\n",
    "    plt.plot(accuracy.values())\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    #return the weight matrix, that contains weights over all epochs\n",
    "    return np.array(wt_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 118
    }
   ],
   "source": [
    "perceptron = SinglePerceptron(.1,10)\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "perceptron.fit(X,y)\n",
    "Y_pred_test = perceptron.predict(X)\n",
    "accuracy_score(Y_pred_test, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class MultiPerceptron(object):\n",
    "   \n",
    "   def __init__(self, niter = 100):\n",
    "       self.niter = niter\n",
    "   \n",
    "   def __sigmoid(self, x):\n",
    "       return 1 / (1 + np.exp(-x))\n",
    "   \n",
    "   def __sigmoid_derivative(self, x):\n",
    "       return (self.__sigmoid(x) * (1-(self.__sigmoid(x))))\n",
    "   def fit(self, X, y):\n",
    "       \"\"\"Fit training data\n",
    "       X : Training vectors, X.shape : [#samples, #features]\n",
    "       y : Target values, y.shape : [#samples]\n",
    "       \"\"\"\n",
    "       # Randomly Initialize Weights\n",
    "       self.weights = 2 * np.random.random((X.shape[1],1)) - 1\n",
    "       for i in range(self.niter):\n",
    "           # Weighted sum of inputs / weights\n",
    "#             print('X:',X, '\\n weights:', self.weights)\n",
    "           self.weighted_sum = np.dot(X, self.weights)\n",
    "#             print('weighted_sum:', self.weighted_sum)\n",
    "           # Activate!\n",
    "           self.activated_output = self.__sigmoid(self.weighted_sum)\n",
    "           # Cac error\n",
    "#             print('y:',np.array(y).reshape(-1,1), '\\n output', self.activated_output)\n",
    "           self.error = np.array(y).reshape(-1,1) - self.activated_output\n",
    "#             print('error:', self.error)\n",
    "#             Update the Weights\n",
    "           self.adjustments = self.error * self.__sigmoid_derivative(self.activated_output)\n",
    "#             print('Adjustments:', self.adjustments)\n",
    "           self.weights += np.dot(X.T, self.adjustments)\n",
    "   def predict(self, X):\n",
    "       \"\"\"Return class label after unit step\"\"\"\n",
    "       return self.__sigmoid(np.dot(X, self.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7229"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 139
    }
   ],
   "source": [
    "multiPre = MultiPerceptron()\n",
    "multiPre.fit(X,y)\n",
    "y_pred_test = multiPre.predict(X)\n",
    "accuracy_score(y_pred_test.round(),y)\n",
    "#Gives a better answer because Multi Perceptron adjusted the weights by using deviative of sigmoid then tries again. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification) d\n",
    "Use an appropriate loss function for a binary classification task d\n",
    "Use an appropriate activation function on the final layer of your network. d\n",
    "Train your model using verbose output for ease of grading. d\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters) d\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment. d\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(303, 14)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n263   63    0   0       108   269    0        1      169      1      1.8   \n46    44    1   2       140   235    0        0      180      0      0.0   \n42    45    1   0       104   208    0        0      148      1      3.0   \n97    52    1   0       108   233    1        1      147      0      0.1   \n226   62    1   1       120   281    0        0      103      0      1.4   \n\n     slope  ca  thal  target  \n263      1   2     2       0  \n46       2   0     2       1  \n42       1   0     2       1  \n97       2   3     3       1  \n226      1   1     3       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>263</th>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>269</td>\n      <td>0</td>\n      <td>1</td>\n      <td>169</td>\n      <td>1</td>\n      <td>1.8</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>44</td>\n      <td>1</td>\n      <td>2</td>\n      <td>140</td>\n      <td>235</td>\n      <td>0</td>\n      <td>0</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>45</td>\n      <td>1</td>\n      <td>0</td>\n      <td>104</td>\n      <td>208</td>\n      <td>0</td>\n      <td>0</td>\n      <td>148</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>52</td>\n      <td>1</td>\n      <td>0</td>\n      <td>108</td>\n      <td>233</td>\n      <td>1</td>\n      <td>1</td>\n      <td>147</td>\n      <td>0</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>281</td>\n      <td>0</td>\n      <td>0</td>\n      <td>103</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 151
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(303, 14)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n12    49    1   1       130   266    0        1      171      0      0.6   \n198   62    1   0       120   267    0        1       99      1      1.8   \n118   46    0   1       105   204    0        1      172      0      0.0   \n151   71    0   0       112   149    0        1      125      0      1.6   \n295   63    1   0       140   187    0        0      144      1      4.0   \n\n     slope  ca  thal  target  \n12       2   0     2       1  \n198      1   2     3       0  \n118      2   0     2       1  \n151      1   0     2       1  \n295      2   2     3       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>49</td>\n      <td>1</td>\n      <td>1</td>\n      <td>130</td>\n      <td>266</td>\n      <td>0</td>\n      <td>1</td>\n      <td>171</td>\n      <td>0</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>62</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120</td>\n      <td>267</td>\n      <td>0</td>\n      <td>1</td>\n      <td>99</td>\n      <td>1</td>\n      <td>1.8</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>105</td>\n      <td>204</td>\n      <td>0</td>\n      <td>1</td>\n      <td>172</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>71</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112</td>\n      <td>149</td>\n      <td>0</td>\n      <td>1</td>\n      <td>125</td>\n      <td>0</td>\n      <td>1.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>63</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>187</td>\n      <td>0</td>\n      <td>0</td>\n      <td>144</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 220
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "data": {
      "text/plain": "              age         sex          cp    trestbps        chol         fbs  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean     0.706056    0.683168    0.322332    0.658119    0.436638    0.148515   \nstd      0.117949    0.466011    0.344017    0.087691    0.091898    0.356198   \nmin      0.376623    0.000000    0.000000    0.470000    0.223404    0.000000   \n25%      0.616883    0.000000    0.000000    0.600000    0.374113    0.000000   \n50%      0.714286    1.000000    0.333333    0.650000    0.425532    0.000000   \n75%      0.792208    1.000000    0.666667    0.700000    0.486702    0.000000   \nmax      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n\n          restecg     thalach       exang     oldpeak       slope          ca  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean     0.264026    0.740826    0.326733    0.167678    0.699670    0.182343   \nstd      0.262930    0.113392    0.469794    0.187270    0.308113    0.255652   \nmin      0.000000    0.351485    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000    0.660891    0.000000    0.000000    0.500000    0.000000   \n50%      0.500000    0.757426    0.000000    0.129032    0.500000    0.000000   \n75%      0.500000    0.821782    1.000000    0.258065    1.000000    0.250000   \nmax      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n\n             thal      target  \ncount  303.000000  303.000000  \nmean     0.771177    0.544554  \nstd      0.204092    0.498835  \nmin      0.000000    0.000000  \n25%      0.666667    0.000000  \n50%      0.666667    1.000000  \n75%      1.000000    1.000000  \nmax      1.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.706056</td>\n      <td>0.683168</td>\n      <td>0.322332</td>\n      <td>0.658119</td>\n      <td>0.436638</td>\n      <td>0.148515</td>\n      <td>0.264026</td>\n      <td>0.740826</td>\n      <td>0.326733</td>\n      <td>0.167678</td>\n      <td>0.699670</td>\n      <td>0.182343</td>\n      <td>0.771177</td>\n      <td>0.544554</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.117949</td>\n      <td>0.466011</td>\n      <td>0.344017</td>\n      <td>0.087691</td>\n      <td>0.091898</td>\n      <td>0.356198</td>\n      <td>0.262930</td>\n      <td>0.113392</td>\n      <td>0.469794</td>\n      <td>0.187270</td>\n      <td>0.308113</td>\n      <td>0.255652</td>\n      <td>0.204092</td>\n      <td>0.498835</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.376623</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.470000</td>\n      <td>0.223404</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.351485</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.616883</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.600000</td>\n      <td>0.374113</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.660891</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.714286</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n      <td>0.650000</td>\n      <td>0.425532</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.757426</td>\n      <td>0.000000</td>\n      <td>0.129032</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.792208</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.700000</td>\n      <td>0.486702</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.821782</td>\n      <td>1.000000</td>\n      <td>0.258065</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 258
    }
   ],
   "source": [
    "target_column = ['target'] \n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "X = df[predictors].values\n",
    "y=df[target_column].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "#\n",
    "#dense = 2 sum of the predicted values from all the neurons in the output layer adds up to one.\n",
    "#Activite WEight, bias, activiation, and layer type\n",
    "#model.compile() configure the learning process.\n",
    "model.add(Dense(500, kernel_initializer = 'random_uniform', bias_initializer='zero', activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From F:\\D3MoNa\\conda\\U4-S1-NLP\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
      "Epoch 1/20\n",
      "\r 32/212 [===>..........................] - ETA: 7s - loss: 0.6923 - acc: 0.4688",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 1s 6ms/step - loss: 0.6600 - acc: 0.7123\n",
      "Epoch 2/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.6306 - acc: 0.6875",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 108us/step - loss: 0.5759 - acc: 0.7925\n",
      "Epoch 3/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.5662 - acc: 0.7188",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 104us/step - loss: 0.4968 - acc: 0.8066\n",
      "Epoch 4/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.5001 - acc: 0.7500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 94us/step - loss: 0.4432 - acc: 0.7972\n",
      "Epoch 5/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4772 - acc: 0.7188",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 90us/step - loss: 0.4084 - acc: 0.7877\n",
      "Epoch 6/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.3851 - acc: 0.8125",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 94us/step - loss: 0.3913 - acc: 0.8160\n",
      "Epoch 7/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.3034 - acc: 0.9062",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 90us/step - loss: 0.3731 - acc: 0.8302\n",
      "Epoch 8/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.2722 - acc: 0.8750",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 90us/step - loss: 0.3750 - acc: 0.8302\n",
      "Epoch 9/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4279 - acc: 0.8125",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 90us/step - loss: 0.3647 - acc: 0.8443\n",
      "Epoch 10/20\n",
      "\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4401 - acc: 0.8438",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 90us/step - loss: 0.3615 - acc: 0.8396\n",
      "Epoch 11/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.3964 - acc: 0.8438",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 90us/step - loss: 0.3466 - acc: 0.8349\n",
      "Epoch 12/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4231 - acc: 0.7500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 90us/step - loss: 0.3462 - acc: 0.8491\n",
      "Epoch 13/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4069 - acc: 0.7500",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 80us/step - loss: 0.3458 - acc: 0.8443\n",
      "Epoch 14/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.2696 - acc: 0.8750",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 85us/step - loss: 0.3388 - acc: 0.8585\n",
      "Epoch 15/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4405 - acc: 0.7812",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 85us/step - loss: 0.3348 - acc: 0.8491\n",
      "Epoch 16/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.4380 - acc: 0.7812",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================] - 0s 80us/step - loss: 0.3531 - acc: 0.8349\n",
      "Epoch 17/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.2227 - acc: 0.9062",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r212/212 [==============================]",
      " - 0s 80us/step - loss: 0.3381 - acc: 0.8443\n",
      "Epoch 18/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.1775 - acc: 0.9688",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 85us/step - loss: 0.3367 - acc: 0.8538\n",
      "Epoch 19/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.2352 - acc: 0.9062",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 80us/step - loss: 0.3235 - acc: 0.8679\n",
      "Epoch 20/20\n\r 32/212 [===>..........................] - ETA: 0s - loss: 0.5259 - acc: 0.7812",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r212/212 [==============================] - 0s 80us/step - loss: 0.3239 - acc: 0.8632\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23ff92137f0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 264
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=20, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy on training data: 0.8679245294265028% \n Error on training data: 0.13207547057349722\nAccuracy on test data: 0.8791208876358284% \n Error on test data: 0.12087911236417159\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "predictions = model.predict(X_train[0:1])\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "def base_model(optimizer='rmsprop', init='normal', dropout_rate =0.0):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(500, kernel_initializer = 'random_uniform', bias_initializer='zero', activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics =['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "# In[10]:\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "model = KerasClassifier(build_fn = base_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "# In[12]:\n",
    "#grid_parameters\n",
    "optimizers = [ 'adam']\n",
    "init = ['normal', 'uniform']\n",
    "dropout_rate = [0.0, 0.2, 0.5]\n",
    "epochs = [1, 3, 5]\n",
    "batches = [1,5,10]\n",
    "param_grid = dict(optimizer = optimizers, init=init, dropout_rate = dropout_rate, nb_epoch = epochs, batch_size=batches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "validator = GridSearchCV(estimator=model, param_grid= param_grid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1/1\n",
      "\r  1/141 [..............................] - ETA: 20:59 - loss: 0.7294 - acc: 0.0000e+00",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/141 [>.............................] - ETA: 2:53 - loss: 0.6647 - acc: 0.5714     ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/141 [=>............................] - ETA: 1:29 - loss: 0.6069 - acc: 0.6923",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/141 [===>..........................] - ETA: 55s - loss: 0.6665 - acc: 0.6000 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/141 [====>.........................] - ETA: 40s - loss: 0.6498 - acc: 0.6154",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 33/141 [======>.......................] - ETA: 30s - loss: 0.6527 - acc: 0.6061",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r 40/141 [=======>......................] - ETA: 23s - loss: 0.6450 - acc: 0.6250",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 46/141 [========>.....................] - ETA: 19s - loss: 0.6363 - acc: 0.6304",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r 54/141 [==========>...................] - ETA: 15s - loss: 0.6267 - acc: 0.6296",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 62/141 [============>.................] - ETA: 12s - loss: 0.6123 - acc: 0.6613",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 69/141 [=============>................] - ETA: 9s - loss: 0.6086 - acc: 0.6667 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 76/141 [===============>..............] - ETA: 8s - loss: 0.5892 - acc: 0.6842",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84/141 [================>.............] - ETA: 6s - loss: 0.5831 - acc: 0.6905",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/141 [==================>...........] - ETA: 5s - loss: 0.5839 - acc: 0.6957",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/141 [====================>.........] - ETA: 4s - loss: 0.5668 - acc: 0.7100",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109/141 [======================>.......] - ETA: 2s - loss: 0.5624 - acc: 0.7156",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r118/141 [========================>.....] - ETA: 1s - loss: 0.5653 - acc: 0.7119",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r127/141 [==========================>...] - ETA: 1s - loss: 0.5636 - acc: 0.7008",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r136/141 [===========================>..] - ETA: 0s - loss: 0.5967 - acc: 0.6838",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
      "\r141/141 [==============================] - 10s 71ms/step - loss: 0.5874 - acc: 0.6950\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "validator.fit(X_train, y_train, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-297-edcb4ce82c06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ],
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error"
    }
   ],
   "source": [
    "print(validator.best_score_)\n",
    "print(validator.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}